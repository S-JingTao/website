<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jingtao Sun</title>

    <meta name="author" content="Jingtao Sun">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jingtao Sun
                </p>
                <p>I am currently a final‑year Ph.D student at <a href="http://robot.hnu.edu.cn/index.htm">NERC-RVC</a> at Hunan University, under supervision of Prof. <a href="http://eeit.hnu.edu.cn/info/1277/4490.htm">Yaonan Wang</a>.
                </p>
                <p>Currently, I am also a visiting scholar at the <a href="https://sites.google.com/view/showlab">Show Lab</a> in the National University of Singpore (NUS), advised by Prof. <a href="https://cde.nus.edu.sg/ece/staff/shou-zheng-mike/">Mike Zheng Shou</a>. 
<!--                   Previously, I worked with Prof. Danwei Wang as well in Nanyang Technological University (NTU).  -->
                  Before that, I received my bachelor’s degree and master’s degree from Hunan University, supervised by Prof. Yaonan Wang.
                </p>
                <p>My current research interests lie at 3D Computer Vision and Robot Learning. Specifically, I am interested in 6-DoF pose estimation, 3D shape reconstruction and multi-modal. I am also interested in diffusion-generating model for 3D vision and generalist robot policy, and applications in real-world robotic tasks.
                </p>
                <strong><span style="color: red;">
                  I am looking for PostDoctoral/Research Fellow position, and if you are interested in my work and research, please drop me an email at jingtaosun@hnu.edu.cn.
                </span></strong>
                <p style="text-align:center">
                  <a href="jingtaosun@hnu.edu.cn">Email</a> &nbsp;/&nbsp;
<!--                   <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp; -->
<!--                   <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=quDjp3MAAAAJ&hl=zh-CN&oi=ao">Scholar</a> &nbsp;/&nbsp;
<!--                   <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/S-JingTao/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/jingtaosun.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/jingtaosun.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected Research</h2>
                <p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="l4d_stop()" onmouseover="l4d_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='l4d_image'><video  width=100% muted autoplay loop>
          <source src="image/l4d.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/l4d.png' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('l4d_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('l4d_image').style.opacity = "0";
          }
          bog_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://s-jingtao.github.io/L4D-Track/">
          <span class="papertitle">L4D-Track: Language-to-4D Modeling Towards 6-DoF Tracking and Shape Reconstruction in 3D Point Cloud Stream
</span>
        </a>
        <br>
        <strong>Jingtao Sun</strong>,
        <a href="">Yaonan Wang</a>,
        <a href="">Mingtao Feng</a>,
        <a href="">Yulan Guo</a>,
        <a href="">Ajmal Mian</a>,
        <a href="">Mike Zheng Shou</a>,	
        <br>
        <em>CVPR</em>, 2024
        <br>
        <a href="https://s-jingtao.github.io/L4D-Track/">project page</a>
        /
        <a href="https://github.com/S-JingTao/L4D_Track">code</a>
        /
        <a href="">arXiv</a>
        <p></p>
        <p>
        our method achieves real-time, causal 6-DoF pose tracking while reconstructing the 3D shape in the current observation. It not only enables zero-shot inference for unseen objects with known categories, but also perfectly showcases the zero-shot capabilities for unseen objects with unknown classes.
        </p>
      </td>
    </tr>

    <tr onmouseout="ick_stop()" onmouseover="ick_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ick_image'><video  width=100% muted autoplay loop>
          <source src="image/ick.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/ick.png' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('ick_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('ick_image').style.opacity = "0";
          }
          bog_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/9982183">
          <span class="papertitle">ICK-Track: A Category-Level 6-DoF Pose Tracker Using Inter-Frame Consistent Keypoints for Aerial Manipulation
</span>
        </a>
        <br>
        <strong>Jingtao Sun</strong>,
        <a href="">Yaonan Wang</a>,
        <a href="">Mingtao Feng</a>,
        <a href="">Danwei Wang</a>,
        <a href="">Jiawen Zhao</a>,
        <a href="">Cyrill Stachniss</a>,
        <a href="">Xieyuanli Chen</a>, 
        <br>
        <em>IROS (Oral Presentation)</em>, 2022
        <br>
        <a href="https://github.com/S-JingTao/Categorical_Pose_Tracking/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=TDmsd99Apzc">video</a>
        /
        <a href="https://ieeexplore.ieee.org/document/9982183">paper</a>
        <p></p>
        <p>
        Developing a real-time category-level object 6-DoF pose tracking that can be applied to aerial manipulation without using any pre-defined object CAD models.
        </p>
      </td>
    </tr>

    <tr onmouseout="m9d_stop()" onmouseover="m9d_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='m9d_image'><video  width=100% muted autoplay loop>
          <source src="image/m9d.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/m9d.png' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('m9d_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('m9d_image').style.opacity = "0";
          }
          m9d_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="">
          <span class="papertitle">Category-Level Multi-object 9D State Tracking Using Object-Centric Multi-scale Transformer in Point Cloud Stream
</span>
        </a>
        <br>
        <strong>Jingtao Sun</strong>,
        <a href="">Yaonan Wang</a>,
        <a href="">Mingtao Feng</a>,
        <a href="">Xiaofeng Guo</a>,
        <a href="">Huimin Lu</a>,
        <a href="">Xieyuanli Chen</a>, 
        <br>
        <em>IEEE Transactions on Multimedia (TMM)</em>, 2023
        <br>
        <a href="">project page</a>
        /
        <a href="">paper</a>
        <p></p>
        <p>
        We focus on category-level multiobject 9-Dimensional (9D) state tracking from the point cloud stream, and propose a novel 9D state estimation network with Kalman-based state optimization to estimate the 6-DoF pose and 3D size of each instance in the scene.
        </p>
      </td>
    </tr>

    <tr onmouseout="srpe_stop()" onmouseover="srpe_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='srpe_image'><video  width=100% muted autoplay loop>
          <source src="image/srpe.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/srpe.png' width=100%>
        </div>
        <script type="text/javascript">
          function bog_start() {
            document.getElementById('srpe_image').style.opacity = "1";
          }

          function bog_stop() {
            document.getElementById('srpe_image').style.opacity = "0";
          }
          srpe_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2403.12728">
          <span class="papertitle">Diffusion-Driven Self-Supervised Learning for Shape Reconstruction and Pose Estimation
</span>
        </a>
        <br>
        <strong>Jingtao Sun</strong>,
        <a href="">Yaonan Wang</a>,
        <a href="">Mingtao Feng</a>,
        <a href="">Chao Ding</a>,
        <a href="">Mike Zheng Shou</a>,
        <a href="">Ajmal Mian</a>, 
        <br>
        <em>arXiv (Under review, submitted to TPAMI)</em>, 2024
        <br>
        <a href="https://github.com/S-JingTao/Self-SRPE">project page</a>
        /
        <a href="https://arxiv.org/abs/2403.12728">arXiv</a>
        <p></p>
        <p>
        Introducing a diffusion-driven self-supervised network for multi-object shape reconstruction and categorical pose estimation, only leveraging the shape priors.
        </p>
      </td>
    </tr>

    <tr onmouseout="rob6d_stop()" onmouseover="rob6d_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='rob6dimage'><video  width=100% muted autoplay loop>
          <source src="image/rob6d.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/rob6d.png' width=100%>
        </div>
        <script type="text/javascript">
          function rob6d_start() {
            document.getElementById('rob6d_image').style.opacity = "1";
          }

          function rob6d_stop() {
            document.getElementById('rob6d_image').style.opacity = "0";
          }
          rob6d_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2401.04377">
          <span class="papertitle">Towards Real-World Aerial Vision Guidance with Categorical 6D Pose Tracker
</span>
        </a>
        <br>
        <strong>Jingtao Sun</strong>,
        <a href="">Yaonan Wang</a>,
        <a href="">Danwei Wang</a>,
        <br>
        <em>arXiv (Under review, submitted to TPAMI)</em>, 2024
        <br>
        <a href="https://github.com/S-JingTao/Categorical_Pose_Tracking">project page</a>
        /
        <a href="https://github.com/S-JingTao/Categorical_Pose_Tracking">video</a>
        /
        <a href="https://arxiv.org/abs/2401.04377">arXiv</a>
        <p></p>
        <p>
        We investigate the real-world robot task of aerial vision guidance for aerial robotics manipulation, utilizing category-level 6-DoF pose tracking.
        </p>
      </td>
    </tr>

    <tr onmouseout="noise_stop()" onmouseover="noise_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='noise_image'><video  width=100% muted autoplay loop>
          <source src="image/noise.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/noise.png' width=100%>
        </div>
        <script type="text/javascript">
          function noise_start() {
            document.getElementById('noise_image').style.opacity = "1";
          }

          function noise_stop() {
            document.getElementById('noise_image').style.opacity = "0";
          }
          noise_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/kendongdong/NoiseMining">
          <span class="papertitle">Pixel-Level Noise Mining for Weakly Supervised Salient Object Detection
</span>
        </a>
        <br>
        <a href="">Mingtao Feng</a>,
        <a href="">Kengdong Liu</a>,
        <a href="">Wei Zhao</a>,
        <strong>Jingtao Sun</strong>,
        <a href="">Yinou Zhang</a>,
        <a href="">Yaonan Wang</a>,
        <a href="">Ajmal Mian</a>,
        <br>
        <em>arXiv (Under review, submitted to TNNLS)</em>, 2024
        <br>
        <a href="">paper</a>
        /
        <a href="https://github.com/kendongdong/NoiseMining">code</a>
        <p></p>
        <p>
        We propose a pixel-level noise mining framework for robust salient object detection by exploiting its own knowledge, and without the need for external models. 
        </p>
      </td>
    </tr>

    <tr onmouseout="hri_stop()" onmouseover="hri_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='hri_image'><video  width=100% muted autoplay loop>
          <source src="image/hri.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/hri.png' width=100%>
        </div>
        <script type="text/javascript">
          function hri_start() {
            document.getElementById('hri_image').style.opacity = "1";
          }

          function hri_stop() {
            document.getElementById('hri_image').style.opacity = "0";
          }
          hri_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/10202561">
          <span class="papertitle">A Fast-Response Dynamic-Static Parallel Attention GCN Network for Body-Hand Gesture Recognition in HRI
</span>
        </a>
        <br>
        <a href="">Xiaofeng Guo</a>,
        <a href="">Qing Zhu</a>,
        <a href="">Yaonan Wang</a>,
        <a href="">Yang Mo</a>,
        <strong>Jingtao Sun</strong>,
        <a href="">Kai Zeng</a>, 
        <a href="">Mingtao Feng</a>,
        <br>
        <em>IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS (TIE)</em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/document/10202561">paper</a>
        <p></p>
        <p>
         We propose a dynamicstatic parallel network for dynamic body gestures and a spatiotemporal graph attention module to improve the graph data fusion effect in the dynamic-static network. Finally, we implement a complete command module to form complete commands with body and hand information for interactions and control of the mobile robot.
        </p>
      </td>
    </tr>

    <tr onmouseout="gdo_stop()" onmouseover="gdo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='gdo_image'><video  width=100% muted autoplay loop>
          <source src="image/gdo.png" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='image/gdo.png' width=100%>
        </div>
        <script type="text/javascript">
          function gdo_start() {
            document.getElementById('gdo_image').style.opacity = "1";
          }

          function gdo_stop() {
            document.getElementById('gdo_image').style.opacity = "0";
          }
          gdo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/10098289">
          <span class="papertitle">Gravitational Discriminative Optimization for Multiview Reconstruction of Free-Form Surface
</span>
        </a>
        <br>
        <a href="">Zijie Wu</a>,
        <a href="">Yaonan Wang</a>,
        <a href="">He Xie</a>,
        <a href="">Mingtao Feng</a>,
        <a href="">Haotian Wu</a>,
        <a href="">Xuebing Liu</a>,
        <strong>Jingtao Sun</strong>,
        <br>
        <em>IEEE/ASME Transactions on Mechatronics (T-Mech)</em>, 2023
        <br>
        <a href="https://ieeexplore.ieee.org/document/10098289">paper</a>
        <p></p>
        <p>
         We propose a novel gravitational discriminative optimization (GDO) method based on a multiview reconstruction framework for shape surface reconstrcution. It consists of a training phase and a reconstruction phase. 
        </p>
      </td>
    </tr>
           
</html>
